{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tX4qkH_B_LWe"
   },
   "source": [
    "# Diffusion Illusions: The Parker Puzzle Demo\n",
    "\n",
    "Hi! Welcome to the official colab demo for our demo \"Diffusion Illusions: Hiding Images in Plain Sight\"\n",
    "\n",
    "By Ryan Burgert, Xiang Li, Abraham Leite, Kanchana Ranasinghe and Michael Ryoo from Stony Brook University\n",
    "\n",
    "Visit our project website: [diffusionillusions.com](https://ryanndagreat.github.io/Diffusion-Illusions/)\n",
    "\n",
    "This project was inspired by our paper \"Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors\". The Peekaboo project website: [https://ryanndagreat.github.io/peekaboo/](https://ryanndagreat.github.io/peekaboo/)\n",
    "\n",
    "Instructions:\n",
    "\n",
    "0. Go to the Runtime menu, and make sure this notebook is using GPU!\n",
    "1. Run the top 2 code cells (one cleans colab's junk and downloads the source code, while the other installs python packages)\n",
    "2. Click 'Runtime', then 'Restart Runtime'. You need to do this the first time you open this notebook to avoid weird random errors from the pip installations.\n",
    "3. Run code cells to load stable diffusion. The first time you run it it will take a few minutes to download; subsequent times won't take long at all though.\n",
    "4. Run all the cells below that, and customize prompt_a and prompt_b!\n",
    "5. Take the result top_image and bottom_image, print them out, and shine a backlight through them like shown in the Diffusion Illusion website (link above!)\n",
    "\n",
    "I may also create a YouTube tutorial if there's interest. Let me know if this would be helpful!\n",
    "\n",
    "This notebook was written by Ryan Burgert. Feel free to reach out to me at rburgert@cs.stonybrook.edu if you have any questions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGDndq0_bch2",
    "outputId": "81a50af6-5861-4990-dfe5-871ac1682d28"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade -r requirements.txt\n",
    "%pip install rp --upgrade\n",
    "# You may need to restart the runtime after installing these\n",
    "# I'm not sure why this helps, but all sorts of weird random errors pop up in Colab if you don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7A1Fw50eDjJ",
    "outputId": "37ceb472-da12-4c74-a76b-a89f39a3a14d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SET YOUR PROMPTS HERE\n",
    "\n",
    "prompt_a = \"A ceramic coffee mug with handle viewed from side and steam rising. Beautiful 4k photography unreal engine 3d \"\n",
    "prompt_b = \"A donut. A shiny frosted chocolate donut. Beautiful 4k photography unreal engine 3d\"\n",
    "\n",
    "\n",
    "#Optional: Specify what you DON'T want to see\n",
    "negative_prompt = 'blurry ugly'\n",
    "\n",
    "print()\n",
    "print('Negative prompt:',repr(negative_prompt))\n",
    "print()\n",
    "print('Chosen prompts:')\n",
    "print('    prompt_a =', repr(prompt_a)) #This will be right-side up\n",
    "print('    prompt_b =', repr(prompt_b)) #This will be upside-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAtxvveUbquu"
   },
   "outputs": [],
   "source": [
    "from rp import *\n",
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import source.stable_diffusion as sd\n",
    "from easydict import EasyDict\n",
    "from source.learnable_textures import LearnableImageFourier\n",
    "from source.stable_diffusion_labels import NegativeLabel\n",
    "from itertools import chain\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "ec572d79f75648e69c18f8fbb8445abe",
      "8a95ebc987364a3cbbc27866ff8c964b",
      "13511603d504480489e9de201dd85211",
      "f72921cdc424455e8d2e86b0ea07a29b",
      "df5753e3d2b54078a5ff58f1f0f5de78",
      "f4b3425062c041b3aa5db68a73ea0a01",
      "eb7e46a3bff547ba8d07ebc87eddd9a0",
      "875b8337c4304ae0b9ea63eb7435d3ba",
      "f767f331f3af45d4a3814a5447d29004",
      "19d10e0e23fa460c8ba196c1691ecef3",
      "38124b85cb824de2a2640dfede710372"
     ]
    },
    "id": "wi9Y9Zp5ejSP",
    "outputId": "b79dad35-3726-4efb-f640-dfb3f27df788"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# 确保你已经安装了 modelscope: pip install modelscope\n",
    "if 's' not in dir():\n",
    "    # --- 1. 配置模型保存的路径 ---\n",
    "    # 使用相对路径（例如当前目录下的 weights 文件夹），这样换电脑也能直接用\n",
    "    model_name = \"./weights/sd-v1-4\"\n",
    "    # --- 2. 自动检查并下载逻辑 ---\n",
    "    if not os.path.exists(model_name):\n",
    "        print(f\"模型路径 {model_name} 不存在，正在通过 ModelScope 自动下载...\")\n",
    "        try:\n",
    "            from modelscope import snapshot_download\n",
    "            snapshot_download('AI-ModelScope/stable-diffusion-v1-4', local_dir=model_name)\n",
    "            print(\"模型下载完成！\")\n",
    "        except ImportError:\n",
    "            raise ImportError(\"请先运行 pip install modelscope 以支持自动下载功能\")\n",
    "    else:\n",
    "        print(f\"检测到本地模型: {model_name}\")\n",
    "gpu=rp.select_torch_device()\n",
    "s=sd.StableDiffusion(gpu,model_name)\n",
    "device=s.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HL_pjdcFekG6"
   },
   "outputs": [],
   "source": [
    "label_a = NegativeLabel(prompt_a,negative_prompt)\n",
    "label_b = NegativeLabel(prompt_b,negative_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LoGGFTkelJJ"
   },
   "outputs": [],
   "source": [
    "#Image Parametrization and Initialization (this section takes vram)\n",
    "\n",
    "#Select Learnable Image Size (this has big VRAM implications!):\n",
    "#Note: We use implicit neural representations for better image quality\n",
    "#They're previously used in our paper \"TRITON: Neural Neural Textures make Sim2Real Consistent\" (see tritonpaper.github.io)\n",
    "# ... and that representation is based on Fourier Feature Networks (see bmild.github.io/fourfeat)\n",
    "learnable_image_maker = lambda: LearnableImageFourier(height=256,width=256,num_features=256,hidden_dim=256,scale=10).to(s.device);SIZE=256\n",
    "\n",
    "image=learnable_image_maker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44f6FT72ems4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#This is the puzzle Matt used in his video!\n",
    "#在autodl上下载，由于网络问题可能很慢，这里我们相比原始代码进行了一些更改\n",
    "import os\n",
    "\n",
    "uv_path = \"assets/parker_puzzle_uv_map.png\"\n",
    "if not os.path.exists(uv_path):\n",
    "    print(\"Downloading UV map...\")\n",
    "    os.makedirs(\"assets\", exist_ok=True)\n",
    "    os.system(\n",
    "        \"wget https://raw.githubusercontent.com/RyannDaGreat/Images/master/test_images/parker_puzzle_uv_map.png \"\n",
    "        \"-O assets/parker_puzzle_uv_map.png\"\n",
    "    )\n",
    "\n",
    "uv_map_b = rp.load_image(uv_path)\n",
    "uv_map_a = rp.get_identity_uv_map(*rp.get_image_dimensions(uv_map_b))\n",
    "\n",
    "\n",
    "rp.display_image(uv_map_a)\n",
    "rp.display_image(uv_map_b)\n",
    "\n",
    "learnable_image_a = lambda: rp.apply_uv_map(image(), uv_map_a)\n",
    "learnable_image_b = lambda: rp.apply_uv_map(image(), uv_map_b)\n",
    "\n",
    "optim=torch.optim.SGD(image.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKCQQg9teoMt"
   },
   "outputs": [],
   "source": [
    "labels=[label_a,label_b]\n",
    "learnable_images=[learnable_image_a,learnable_image_b]\n",
    "\n",
    "#The weight coefficients for each prompt. For example, if we have [0,1], then only the upside-down mode will be optimized\n",
    "weights=[1,1]\n",
    "\n",
    "weights=rp.as_numpy_array(weights)\n",
    "weights=weights/weights.sum()\n",
    "weights=weights*len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWpLV_Toertv"
   },
   "outputs": [],
   "source": [
    "#For saving a timelapse\n",
    "ims=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6-FlVZPes09"
   },
   "outputs": [],
   "source": [
    "def get_display_image():\n",
    "    return rp.tiled_images(\n",
    "        [\n",
    "            rp.as_numpy_image(learnable_image_a()),\n",
    "            rp.as_numpy_image(learnable_image_b()),\n",
    "        ],\n",
    "        length=len(learnable_images),\n",
    "        border_thickness=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "id": "bB-Uv4Y5et8J",
    "outputId": "0cf6d601-40a6-4140-f0c5-e4720d389822"
   },
   "outputs": [],
   "source": [
    "NUM_ITER=5000\n",
    "\n",
    "#Set the minimum and maximum noise timesteps for the dream loss (aka score distillation loss)\n",
    "s.max_step=MAX_STEP=990\n",
    "s.min_step=MIN_STEP=10 \n",
    "\n",
    "television = rp.JupyterDisplayChannel()\n",
    "television.display()\n",
    "\n",
    "display_eta=rp.eta(NUM_ITER, title='Status')\n",
    "\n",
    "DISPLAY_INTERVAL = 200\n",
    "\n",
    "print('Every %i iterations we display an image in the form [image_a, image_b], where'%DISPLAY_INTERVAL)\n",
    "print('    image_a = (the right-side up image)')\n",
    "print('    image_b = (image_a, but upside down)')\n",
    "print()\n",
    "print('Interrupt the kernel at any time to return the currently displayed image')\n",
    "print('You can run this cell again to resume training later on')\n",
    "print()\n",
    "print('Please expect this to take quite a while to get good images (especially on the slower Colab GPU\\'s)! The longer you wait the better they\\'ll be')\n",
    "\n",
    "try:\n",
    "    for iter_num in range(NUM_ITER):\n",
    "        display_eta(iter_num) #Print the remaining time\n",
    "\n",
    "        preds=[]\n",
    "        for label,learnable_image,weight in rp.random_batch(list(zip(labels,learnable_images,weights)), batch_size=1):\n",
    "            pred=s.train_step(\n",
    "                label.embedding,\n",
    "                learnable_image()[None],\n",
    "\n",
    "                #PRESETS (uncomment one):\n",
    "                noise_coef=.1*weight,guidance_scale=100,#10\n",
    "                # noise_coef=0,image_coef=-.01,guidance_scale=50,\n",
    "                # noise_coef=0,image_coef=-.005,guidance_scale=50,\n",
    "                # noise_coef=.1,image_coef=-.010,guidance_scale=50,\n",
    "                # noise_coef=.1,image_coef=-.005,guidance_scale=50,\n",
    "                # noise_coef=.1*weight, image_coef=-.005*weight, guidance_scale=50,\n",
    "            )\n",
    "            preds+=list(pred)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if iter_num and not iter_num%(DISPLAY_INTERVAL*50):\n",
    "                #Wipe the slate every 50 displays so they don't get cut off\n",
    "                from IPython.display import clear_output\n",
    "                clear_output()\n",
    "\n",
    "            if not iter_num%(DISPLAY_INTERVAL//4):\n",
    "                im = get_display_image()\n",
    "                ims.append(im)\n",
    "                television.update(im)\n",
    "                \n",
    "                if not iter_num%DISPLAY_INTERVAL:\n",
    "                    rp.display_image(im)\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "except KeyboardInterrupt:\n",
    "    print()\n",
    "    print('Interrupted early at iteration %i'%iter_num)\n",
    "    im = get_display_image()\n",
    "    ims.append(im)\n",
    "    rp.display_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwhrgJiie3mX"
   },
   "outputs": [],
   "source": [
    "print('Unsolved Image:')\n",
    "rp.display_image(rp.as_numpy_image(learnable_image_a()))\n",
    "\n",
    "print('Solved Image:')\n",
    "rp.display_image(rp.as_numpy_image(learnable_image_b()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YJJw4dXe4JJ"
   },
   "outputs": [],
   "source": [
    "def save_run(name):\n",
    "    folder=\"untracked/parker_puzzle_runs/%s\"%name\n",
    "    if rp.path_exists(folder):\n",
    "        folder+='_%i'%time.time()\n",
    "    rp.make_directory(folder)\n",
    "    ims_names=['ims_%04i.png'%i for i in range(len(ims))]\n",
    "    with rp.SetCurrentDirectoryTemporarily(folder):\n",
    "        rp.save_images(ims,ims_names,show_progress=True)\n",
    "    print()\n",
    "    print('Saved timelapse to folder:',repr(folder))\n",
    "    \n",
    "save_run('-'.join([prompt_a,prompt_b])) #You can give it a good custom name if you want!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python diffilu",
   "language": "python",
   "name": "diffilu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
