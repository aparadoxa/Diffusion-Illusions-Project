{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade -r requirements.txt\n",
    "%pip install rp --upgrade\n",
    "# You may need to restart the runtime after installing these\n",
    "# I'm not sure why this helps, but all sorts of weird random errors pop up in Colab if you don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import source.stable_diffusion as sd\n",
    "from easydict import EasyDict\n",
    "from source.learnable_textures import LearnableImageFourier\n",
    "from source.stable_diffusion_labels import NegativeLabel\n",
    "from itertools import chain\n",
    "import time\n",
    "import torchvision.transforms.functional as TF\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 确保你已经安装了 modelscope: pip install modelscope\n",
    "if 's' not in dir():\n",
    "    # --- 1. 配置模型保存的路径 ---\n",
    "    # 使用相对路径（例如当前目录下的 weights 文件夹），这样换电脑也能直接用\n",
    "    model_name = \"./weights/sd-v1-4\"\n",
    "    # --- 2. 自动检查并下载逻辑 ---\n",
    "    if not os.path.exists(model_name):\n",
    "        print(f\"模型路径 {model_name} 不存在，正在通过 ModelScope 自动下载...\")\n",
    "        try:\n",
    "            from modelscope import snapshot_download\n",
    "            snapshot_download('AI-ModelScope/stable-diffusion-v1-4', local_dir=model_name)\n",
    "            print(\"模型下载完成！\")\n",
    "        except ImportError:\n",
    "            raise ImportError(\"请先运行 pip install modelscope 以支持自动下载功能\")\n",
    "    else:\n",
    "        print(f\"检测到本地模型: {model_name}\")\n",
    "gpu=rp.select_torch_device()\n",
    "s=sd.StableDiffusion(gpu,model_name)\n",
    "device=s.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ff608",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_list = [\n",
    "    \"a snowy rocky mountain\",          # Static View (原图)\n",
    "     \"a giant panda face\"    # Motion Blurred View (晃动后)\n",
    "]\n",
    "\n",
    "# 动态模糊设置\n",
    "BLUR_ANGLE = -45.0       # 晃动角度 (45度对角线)\n",
    "BLUR_KERNEL_SIZE = 31   # 模糊核大小 (越大越模糊)\n",
    "SIZE = 256              # 图片分辨率\n",
    "\n",
    "negative_prompt = 'ugly, inconsistent colors'\n",
    "print(f\"\\n=== Motion Blur Illusion Setup ===\")\n",
    "print(f\"Angle: {BLUR_ANGLE}°, Kernel Size: {BLUR_KERNEL_SIZE}\")\n",
    "print(f\"View 1 (Static): {prompts_list[0]}\")\n",
    "print(f\"View 2 (Motion): {prompts_list[1]}\")\n",
    "\n",
    "labels = [NegativeLabel(p, negative_prompt) for p in prompts_list]\n",
    "N = len(prompts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "learnable_image_maker = lambda: LearnableImageFourier(height=SIZE, width=SIZE, hidden_dim=256, num_features=128).to(s.device)\n",
    "main_image = learnable_image_maker()\n",
    "\n",
    "# 创建运动模糊核\n",
    "def get_motion_blur_kernel(kernel_size, angle_degrees):\n",
    "    # 1. 生成水平线\n",
    "    kernel = torch.zeros((kernel_size, kernel_size))\n",
    "    center = kernel_size // 2\n",
    "    kernel[center, :] = 1.0\n",
    "    \n",
    "    # 2. 旋转\n",
    "    kernel = kernel.unsqueeze(0).unsqueeze(0) # [1,1,H,W]\n",
    "    kernel = TF.rotate(kernel, angle_degrees, interpolation=TF.InterpolationMode.BILINEAR)\n",
    "    kernel = kernel / kernel.sum() # 归一化\n",
    "    \n",
    "    kernel = kernel.repeat(3, 1, 1, 1)\n",
    "    return kernel.to(device)\n",
    "\n",
    "blur_kernel = get_motion_blur_kernel(BLUR_KERNEL_SIZE, BLUR_ANGLE)\n",
    "\n",
    "# 索引 0: 返回原图\n",
    "# 索引 1: 返回模糊后的图\n",
    "learnable_images = [\n",
    "    (lambda: main_image()), \n",
    "    (lambda: F.conv2d(main_image(), blur_kernel, padding=BLUR_KERNEL_SIZE//2, groups=3))\n",
    "]\n",
    "\n",
    "params = chain(main_image.parameters())\n",
    "optim = torch.optim.SGD(params, lr=1e-4)\n",
    "\n",
    "# 权重设置 (通常模糊后的 Loss 需要大一点)\n",
    "weights = [1.0, 1.5] \n",
    "weights = rp.as_numpy_array(weights)\n",
    "weights = weights / weights.sum() * len(weights) # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46732a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = []\n",
    "\n",
    "def get_display_image():\n",
    "    current_views = [rp.as_numpy_image(img_func()) for img_func in learnable_images]\n",
    "    \n",
    "    final_image = rp.tiled_images(\n",
    "        current_views, \n",
    "        length=2, \n",
    "        border_thickness=5, \n",
    "        border_color=(255,255,255)\n",
    "    )\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER = 4000         \n",
    "DISPLAY_INTERVAL = 200   \n",
    "\n",
    "s.max_step = 980\n",
    "s.min_step = 10 \n",
    "\n",
    "display_eta = rp.eta(NUM_ITER, title='Status: ')\n",
    "\n",
    "print(f'Starting training for Motion Blur Illusion...')\n",
    "print(f'Left Image: Static ({prompts_list[0]})')\n",
    "print(f'Right Image: Motion Blurred ({prompts_list[1]})')\n",
    "print(f'Check output every {DISPLAY_INTERVAL} iterations (History kept).')\n",
    "\n",
    "try:\n",
    "    for iter_num in range(NUM_ITER):\n",
    "        display_eta(iter_num) \n",
    "\n",
    "        preds = []\n",
    "\n",
    "        for label, learnable_image_func, weight in rp.random_batch(list(zip(labels, learnable_images, weights)), batch_size=1):\n",
    "            pred = s.train_step(\n",
    "                label.embedding,\n",
    "                learnable_image_func()[None], # 调用 lambda 获取当前视角的 tensor\n",
    "                noise_coef=0.1 * weight,\n",
    "                guidance_scale=60,\n",
    "            )\n",
    "            preds += list(pred)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if not iter_num % DISPLAY_INTERVAL:\n",
    "                im = get_display_image()\n",
    "                ims.append(im)\n",
    "                print(f\"\\n--- Iteration {iter_num} ---\")\n",
    "                rp.display_image(im)\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print()\n",
    "    print('Interrupted early at iteration %i' % iter_num)\n",
    "    im = get_display_image()\n",
    "    ims.append(im)\n",
    "    rp.display_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Final Result ===\")\n",
    "final_static_tensor = main_image()\n",
    "final_blurred_tensor = F.conv2d(final_static_tensor, blur_kernel, padding=BLUR_KERNEL_SIZE//2, groups=3)\n",
    "img_static = rp.as_numpy_image(final_static_tensor)\n",
    "img_blurred = rp.as_numpy_image(final_blurred_tensor)\n",
    "print(f\"\\n[1] Static View (Should look like: {prompts_list[0]})\")\n",
    "rp.display_image(img_static)\n",
    "print(f\"\\n[2] Motion Blurred View (Angle: {BLUR_ANGLE}°, Should look like: {prompts_list[1]})\")\n",
    "rp.display_image(img_blurred)\n",
    "print(\"\\n[3] Side-by-Side Comparison\")\n",
    "comparison = rp.tiled_images([img_static, img_blurred], length=2)\n",
    "rp.display_image(comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
